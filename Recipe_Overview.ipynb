{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\u}{\\mathbf{u}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "%\n",
       "% Test set\n",
       "\\newcommand{\\xt}{\\underline{\\x}}\n",
       "\\newcommand{\\yt}{\\underline{\\y}}\n",
       "\\newcommand{\\Xt}{\\underline{\\X}}\n",
       "\\newcommand{\\perfm}{\\mathcal{P}}\n",
       "%\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{Thetam}{\\Theta_{-0}}\n",
       "\n",
       "% CNN\n",
       "\\newcommand{\\kernel}{\\mathbf{k}} \n",
       "\\newcommand{\\dim}{d}\n",
       "\\newcommand{\\idxspatial}{{\\text{idx}}}\n",
       "\\newcommand{\\summaxact}{\\text{max}}\n",
       "%\n",
       "%\n",
       "\n",
       "% RNN\n",
       "% \\tt indexes a time step\n",
       "\\newcommand{\\tt}{t}\n",
       "\\newcommand{\\tp}{{(\\tt)}}\n",
       "%\n",
       "%\n",
       "\n",
       "% LSTM\n",
       "\\newcommand{\\g}{\\mathbf{g}}\n",
       "\\newcommand{\\remember}{\\mathbf{remember}}\n",
       "\\newcommand{\\save}{\\mathbf{save}}\n",
       "\\newcommand{\\focus}{\\mathbf{focus}}\n",
       "%\n",
       "%\n",
       "% NLP\n",
       "\\newcommand{\\Vocab}{\\mathbf{V}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\offset}{o}\n",
       "\\newcommand{\\o}{o}\n",
       "\\newcommand{\\E}{\\mathbf{E}}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "%                     \n",
       "\\newcommand{\\pdata}{p_\\text{data}}\n",
       "\\newcommand{\\pmodel}{p_\\text{model}}\n",
       "%\n",
       "% SVM\n",
       "\\newcommand{\\margin}{{\\mathbb{m}}}\n",
       "\\newcommand{\\lmk}{\\boldsymbol{\\ell}}\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "\\def\\trans#1{\\dot{#1}}\n",
       "\\def\\transx{\\trans{\\x}}\n",
       "\\def\\transy{\\trans{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\prc#1#2{\\mathcal{p}(#1 \\; | \\; #2)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "%\n",
       "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
       "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
       "%\n",
       "\\def\\loc#1{{\\text{##} {#1}}}\n",
       "%\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Latex_macros.ipynb\n",
    "%run beautify_plots.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is the \"Recipe\" for Machine Learning\n",
    "\n",
    "We will define a methodical approach to solve problems using Machine Learning.\n",
    "\n",
    "This is the *Recipe for Machine Learning*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Recipe for Machine Learning</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/W1_L3_S4_ML_Process.png\" width=\"100%\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "​"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "There are no short-cuts !\n",
    "\n",
    "Each step in the Recipe  both prepares you for the next and, crucially, gives you *deeper insight*\n",
    "which improves the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Plan\n",
    "- Will illustrate the recipe using a model familiar to you: Linear Regression\n",
    "- **This will be a sprint**\n",
    "    - illustrate the steps in the Recipe\n",
    "    - will be followed by a deeper dive into the steps and the mathematics\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Since this is our first lecture involving code\n",
    "- I will show a lot more code within this notebook than in subsequent notebooks\n",
    "- In the future, most of this code will be moved to separate modules\n",
    "    - re-usable as a module, rather than copy/paste between notebooks\n",
    "    - notebooks are less cluttered; maintain focus on the problem, not the code\n",
    "- I will digress from the problem in order to solidify  your understanding of the tools: \n",
    "    - Jupyter, Pandas, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The particular task with which we illustrate the Recipe is Regression, a form of Supervised Learning.\n",
    "- Using numerical features and target\n",
    "- We will introduce categorical variables (features/targets) in a following lecture\n",
    "- Focus is on the *concept*, not the code\n",
    "- Let's jump in ! Start *doing* ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <b>Disclaimer:</b> \n",
    "    <br>\n",
    "    The purpose of this lecture is <i>not</i> to make you an expert in sklearn. \n",
    "    <br>\n",
    "    It is to introduce you to concepts that you can apply no matter what toolkit you use in the future.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Get the data\n",
    "\n",
    "The first step is obtaining data for training and evaluation.\n",
    "\n",
    "This is often the most challenging part !\n",
    "- Interesting data is scattered: requires collection\n",
    "- Supervised Learning requires labeled data; where do the labels come from ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In this course, we will usually provide you with data so you will be mostly insulated from this challenge.\n",
    "- Learning how to obtain data is a good skill to learn\n",
    "    - Web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's visit the notebook section [Get the Data](Recipe_for_ML.ipynb#Recipe-step-A:-Get-the-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Look at the data\n",
    "\n",
    "Always put your eyes on the data !\n",
    "- You will learn about its \"shape\":\n",
    "    - tabular ?  What are the attribute names ?\n",
    "    - What are the types of the attributes ? Numeric ? Text ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- You will learn about potential data problems\n",
    "    - missing data\n",
    "    - strange values\n",
    "    \n",
    "Don't even try to do anything with your data until you have at least the most basic understanding by\n",
    "performing an inspection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's visit the notebook and [Look at the data](Recipe_for_ML.ipynb#Recipe-A.2:-Have-a-look-at-the-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Define a Performance Measure\n",
    "\n",
    "Our model \"learns\" from training data, so we might expect it to predict well on training examples\n",
    "- the training examples are *in sample*: used by the model to learn $\\Theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How well should I expect the model to predict on  examples not encountered during training ?\n",
    "- \"test\" examples never seen during training, called *out of sample* examples\n",
    "\n",
    "We define a *Performance Measure* to measure how well the model performs out of sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's visit the notebook and [Define a Performance Measure](Recipe_for_ML.ipynb#select_performance_measure)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Performance Measure versus Loss Function\n",
    "\n",
    "There may some confusion between the Performance Measure and Loss functions\n",
    "- they are both evaluated over a set of examples\n",
    "- they both measure performance of some sort\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A Performance Measure can be thought of as the promise you make\n",
    "- to a client/customer/boss\n",
    "- on how well your model will perform on arbitrary, yet to be seen examples (non-training, out-of-sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In order for you to have confidence in your promise\n",
    "- you evaluate the Performance Measure on *out of sample* examples\n",
    "- using the out of sample examples *once* so that your model doesn't learn from them (i.e., become in-sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To illustrate, let\n",
    "- $\\X$ denote our set of training examples, $\\x^\\ip \\in \\X$\n",
    "- $\\Xt$ denote a set of test examples (out of sample: not used in training), $\\xt^\\ip \\in \\Xt$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Loss on  <i>Training example</i></center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/W1_L4_s15_Intro_training.jpg\" width=\"70%\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "​"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Performance on  <i>Test example</i></center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/W2_L2_S15_Performance_measure.png\" width=\"70%\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "​"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- A Performance Measure\n",
    "    - is a property of the *problem* (not the model used to solve the problem)\n",
    "    - you may have more than one Performance Measure\n",
    "        - each expressing some desired quality of the prediction\n",
    "    - is evaluated *out of sample*, that is, on non-training examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The Loss Function\n",
    "    - is a property of a *model*: it guides a particular model's search for the best $\\Theta$\n",
    "        - different models may have different Loss Functions\n",
    "            - but the *problem's* Performance Metric is the same\n",
    "    - is evaluated *in sample*, that is, on training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Create a test set\n",
    "\n",
    "Let's visit the notebook and [Create a test set](Recipe_for_ML.ipynb#Recipe-A.4:-Create-a-test-set-and-put-it-aside-!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "This is one of the key steps of a good Data Scientist.\n",
    "\n",
    "Besides \"seeing\" the data, we need to hear it: what is it telling us that may aid prediction\n",
    "\n",
    "- Any problems with the data that would inhibit learning ?\n",
    "- Any obviously useful predictive features ?\n",
    "    - relationship between target and a single feature ?\n",
    "    - relationship between target and combinations of features ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Any more complex relationships that may be useful ?\n",
    "- Relationship *between* features ?\n",
    "- Relative magnitudes of features ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Often,  understanding the data intimately can lead to\n",
    "- transformations of the features that will aid prediction\n",
    "- improved models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's visit the notebook and perform [Exploratory Data Analysis](Recipe_for_ML.ipynb#Recipe-Step-B:-Exploratory-Data-Analysis-(EDA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Prepare the data\n",
    "\n",
    "It is not always the case that the data in \"raw\" form is adequate for modeling\n",
    "- Cleanliness\n",
    "    - dealing with missing data or anomalous values\n",
    "- Numericalization\n",
    "    - Converting non-numeric/categorical data into appropriate numbers\n",
    "- Scaling, normalization\n",
    "    - putting features on compatible scales\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A key part of the Prepare the Data step is *feature engineering* or *transformations*\n",
    "- Creating new, synthetic features from the \"raw\" features\n",
    "- Knowing when/how to do this is what separates a good Data Scientist from an average one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We will devote parts of several subsequent modules to the important topic of Transformations.\n",
    "- Our initial pass over this subject will be minimal\n",
    "- So that we have enough time to explore the other steps in the Recipe\n",
    "\n",
    "Let's visit the notebook [Prepare the data](Recipe_for_ML.ipynb#Recipe-Step-C:-Prepare-the-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Train a model\n",
    "\n",
    "The model is our \"predictor\": the machine that takes features and produces predictions.\n",
    "\n",
    "All the prior steps of the recipe were \"prep-work\": preparing the ingredients (data) for cooking (modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Unlike actual cooking, this step is *iterative*\n",
    "- Try a simple model, fit it to the data and evaluate the results\n",
    "- Perform Error Analysis: Examine the results critically\n",
    "    - Have our changes improved the Loss ? Is the Loss value acceptable ?\n",
    "    - Is there some commonality among the examples with \"bad\" predictions ?\n",
    "        - Can we change the model or perform Feature Engineering to compensate for common errors ?\n",
    "        - Perform Feature Engineering, modify the model. \n",
    "- Repeat !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Iterative training</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/W2_L2_S27_ML_process_iterate.png\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "​"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The iterative nature is often overlooked in the rush to learn as many models as possible.\n",
    "\n",
    "The lessons learned from the Error Analysis is how we systematically progress from\n",
    "- Simple but poor models\n",
    "- To better models of increasing complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Select a model and train it\n",
    "Let's move to the notebook and [Select and Train a model](Recipe_for_ML.ipynb#Recipe-Step-D:-Train-a-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Validation and Cross Validation\n",
    "\n",
    "We have just fit our first model and evaluated the Performance Measure on the test examples.\n",
    "\n",
    "Can we continue trying to improve the model and re-evaluate the Performance metric on the same test examples ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "No !  By seeing the \"out of sample\" examples, we have made them \"in-sample\"\n",
    "- We can improve our model by causing it to perform well on the test examples\n",
    "- Result won't be a realistic measure of performance on unseen examples\n",
    "    - Like seeing the questions before the exam !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Fortunately, there is a way to both\n",
    "- save your test examples for single use\n",
    "- create pseudo-test examples that can be reused\n",
    "\n",
    "Let's return to the notebook and explore [Validation and Cross Validation](Recipe_for_ML.ipynb#Recipe-D.3:--Validation-and-Cross-Validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Error analysis\n",
    "\n",
    "Now that we have fit a model, we have \n",
    "- an estimate of Performance Measure using Validation/Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If this measures is not \"good enough\", we will want to improve predictions\n",
    "- we might improve prediction by *changing* to a different model\n",
    "- we might improve prediction by *adding features*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How do we know if the Performance Measure is \"good enough\" and how to improve our model ?\n",
    "\n",
    "Unfortunately, many people (and courses!) don't explore this enough.\n",
    "\n",
    "Let's move to the notebook to [Examine the errors](Recipe_for_ML.ipynb#Recipe-D.4:--Error-analysis)\n",
    "to see why a deeper analysis may be warranted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Iterate: Linear Regression with higher order features\n",
    "\n",
    "The Error Analysis we performed on our first model (single non-constant feature) suggested a need for improvement.\n",
    "\n",
    "Two types of improvement come to mind\n",
    "- Hypothesis iteration: try  a different model\n",
    "    \n",
    "- Feature iteration: change/add to the features of the current model\n",
    "    - adding a previously discarded feature\n",
    "    - creating a synthetic feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will take the approach of adding a feature.\n",
    "\n",
    "Let's extend Linear Regression with [higher order features](Linear_Regression_HigherOrderFeatures.ipynb) (separate notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## When to stop iterating\n",
    "\n",
    "Adding second order features resulted in a perfect in-sample fit, so there is no point iterating further.\n",
    "\n",
    "In general, this will not be the case.\n",
    "\n",
    "How do we know that our model is \"good enough\" ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We encourage you to do a Deeper Dive by examining the topic of [Bias and Variance](Bias_and_Variance.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fine tune\n",
    "\n",
    "There are often \"tweaks\" that can be applied to a near-final model in order to squeeze out increase\n",
    "performance.\n",
    "\n",
    "For example: many models have *hyper parameters*.\n",
    "\n",
    "These are values that are *chosen* at model construction, rather than *discovered* by fitting during training ($\\Theta$)\n",
    "\n",
    "- the degree $d$ of the polynomial when constructing higher order features $\\x^d$\n",
    "- whether to include/exclude the intercept $\\Theta_0$ in a Linear Regression\n",
    "- strength of the regularization penalty (coming attraction: to be discussed together with the Loss function)\n",
    "- the $k$ in K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Perhaps a different choice of a hyper-parameter would improve the model ?\n",
    "\n",
    "We can try many choices before settling on the one giving the best Performance Metric.\n",
    "\n",
    "Hyper parameters search is another reason for using Cross Validation\n",
    "- we can't use the Test set more than once\n",
    "- with a single Validation set: we might overfit to the validation set\n",
    "    - that is, choose a value for the hyper parameter that is best for this *single* validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We encourage  you to do a Deeper Dive by examining the topic of [Fine Tuning](Fine_tuning.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recap\n",
    "\n",
    "- We have briefly detailed the multi-step process for Machine Learning\n",
    "- This should be a model for you (and your assignments !)\n",
    "- We will explore some of the steps in greater depth in future modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done !\n"
     ]
    }
   ],
   "source": [
    "print(\"Done !\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "370.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
